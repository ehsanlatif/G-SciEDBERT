{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0lTwJkEZzlE"
   },
   "source": [
    "# MultiClass Classification in 10 Minutes with BERT-TensorFlow and SoftMax\n",
    "- Based on Article  \n",
    "  https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-bert-and-hugging-face-294e8a04b671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uaywxYQ7Owcs"
   },
   "source": [
    "- Data Source:\n",
    "  - Unzip files (only one time after downloading tar.gz file)  \n",
    "  http://qwone.com/~jason/20Newsgroups/\n",
    "\n",
    "  - Download Link:  \n",
    "    http://qwone.com/~jason/20Newsgroups/20news-bydate.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.18\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07aNXeymDgN6"
   },
   "source": [
    "## Install Transformers Python Library to run it in CoLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpyyhRtWZxzD",
    "outputId": "9fd59259-a67d-489f-abde-89fa54b58257"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss, BCELoss\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, f1_score, accuracy_score\n",
    "import pickle\n",
    "from transformers import *\n",
    "from tqdm import tqdm, trange\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "19qhcXnnDvbu"
   },
   "source": [
    "## Mount Google Drive to Read Data & Model from Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wlpTiHEUbLy",
    "outputId": "e5957b80-576c-400f-dff0-77728ec7ad0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "#if device_name != '/device:GPU:0':\n",
    "#  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mz2Fbv26sc9T",
    "outputId": "c4e49b2e-523c-4ff8-a492-c344119d6135"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A5000'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "-Pbjz0hNU920"
   },
   "outputs": [],
   "source": [
    "dataset_name = 'S327Q02'\n",
    "#sub_dataset = 'gender2'\n",
    "train_data_file = '../dataset/extracted_files/'+dataset_name+'_train.csv'\n",
    "output_model_name = '../models/G-SciEdBERT_model_'+dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZeObzsGqsrnz",
    "outputId": "8ca4a0f1-85e7-4222-deeb-84b63514c28c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das bei ebbe weniger strom durch die turbinnen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es könnten Überschwemmungen auftreten.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die Turbinen sind sehr laut und liefern wenig ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man kann die Stromerzeugung bei einem Gezeiten...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bei einem Gezeitenkraftwerk muss man sich auf ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  das bei ebbe weniger strom durch die turbinnen...    0.0\n",
       "1             es könnten Überschwemmungen auftreten.    0.0\n",
       "2  Die Turbinen sind sehr laut und liefern wenig ...    0.0\n",
       "3  Man kann die Stromerzeugung bei einem Gezeiten...    0.0\n",
       "4  Bei einem Gezeitenkraftwerk muss man sich auf ...    0.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(train_data_file)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OpRmTUuvxrxc",
    "outputId": "09312305-ddf0-4eae-a480-7c082bd02687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comments in training:  False\n",
      "Null values in training:  False\n",
      "Null values after drop in training:  False\n"
     ]
    }
   ],
   "source": [
    "print('Unique comments in training: ', train_df.sentence.nunique() == train_df.shape[0])\n",
    "print('Null values in training: ', train_df.isnull().values.any())\n",
    "train_df = train_df.dropna()\n",
    "print('Null values after drop in training: ', train_df.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edZccb-2lfBt",
    "outputId": "ada145e5-dd36-4b9b-94d8-920fd3ac0ca5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'] = pd.Categorical(train_df.score, ordered=False).codes\n",
    "train_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "US-USWoale2_",
    "outputId": "baeff17a-0a88-4123-a85c-fd62232a3035"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2Index :{(0.0, 0): {}}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "mapLabels = pd.DataFrame(train_df.groupby(['score', 'label']).count())\n",
    "\n",
    "#drop count column\n",
    "mapLabels.drop(['sentence'], axis = 1, inplace = True)\n",
    "label2Index = mapLabels.to_dict(orient='index')\n",
    "\n",
    "print (f\"label2Index :{label2Index}\")\n",
    "print (type(label2Index))\n",
    "#print (f\"index2Label :{index2Label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jn-6gvAyuZcC",
    "outputId": "68ac16e6-ec9d-4869-ede9-c70a82ecd3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> 0.0\n"
     ]
    }
   ],
   "source": [
    "index2label = {}\n",
    "\n",
    "for key in label2Index:\n",
    "  print (f\"{key[1]} -> {key[0]}\")\n",
    "  index2label[key[1]] = key[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TJeeIA0sx1kN",
    "outputId": "e4881ae3-de0c-408b-b934-fe2995e7386b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2Index: {0.0: 0}\n",
      "index2label: {0: 0.0}\n"
     ]
    }
   ],
   "source": [
    "label2Index = {v: k for k, v in index2label.items()}\n",
    "\n",
    "print (f'label2Index: {label2Index}')\n",
    "print (f'index2label: {index2label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "XwcbgaeYyb0d",
    "outputId": "c21ae39f-0e8b-414c-b71d-ecb7b67161e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>das bei ebbe weniger strom durch die turbinnen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es könnten Überschwemmungen auftreten.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Die Turbinen sind sehr laut und liefern wenig ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Man kann die Stromerzeugung bei einem Gezeiten...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bei einem Gezeitenkraftwerk muss man sich auf ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score  label\n",
       "0  das bei ebbe weniger strom durch die turbinnen...    0.0      0\n",
       "1             es könnten Überschwemmungen auftreten.    0.0      0\n",
       "2  Die Turbinen sind sehr laut und liefern wenig ...    0.0      0\n",
       "3  Man kann die Stromerzeugung bei einem Gezeiten...    0.0      0\n",
       "4  Bei einem Gezeitenkraftwerk muss man sich auf ...    0.0      0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "W4YNoaoDaK5v"
   },
   "outputs": [],
   "source": [
    "train_df.rename(columns = {'label' : 'LABEL_COLUMN', 'sentence' : 'DATA_COLUMN'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "Crrzuh66bsgT"
   },
   "outputs": [],
   "source": [
    "# Remoe Email address to avoid additional noise\n",
    "train_df.DATA_COLUMN.replace(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', '', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "WlfQrabQ0XJc"
   },
   "outputs": [],
   "source": [
    "train_df = train_df[['LABEL_COLUMN','DATA_COLUMN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RMkmS0d-aKuX",
    "outputId": "f7613199-6e11-4088-f83a-9b2205d2964f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>das bei ebbe weniger strom durch die turbinnen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>es könnten Überschwemmungen auftreten.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Die Turbinen sind sehr laut und liefern wenig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Man kann die Stromerzeugung bei einem Gezeiten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Bei einem Gezeitenkraftwerk muss man sich auf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL_COLUMN                                        DATA_COLUMN\n",
       "0             0  das bei ebbe weniger strom durch die turbinnen...\n",
       "1             0             es könnten Überschwemmungen auftreten.\n",
       "2             0  Die Turbinen sind sehr laut und liefern wenig ...\n",
       "3             0  Man kann die Stromerzeugung bei einem Gezeiten...\n",
       "4             0  Bei einem Gezeitenkraftwerk muss man sich auf ..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l6Jm1uNuc-ek",
    "outputId": "8c729600-73e5-4611-c519-d824c9683e48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LABEL_COLUMN    686\n",
       "DATA_COLUMN     686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-KRMQGfc-bE",
    "outputId": "0b83f9bf-e01a-4232-bc54-c76f9798242c"
   },
   "outputs": [],
   "source": [
    "#splitSize = df.count() * .8\n",
    "#splitSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5w5qeWTLc-XG"
   },
   "outputs": [],
   "source": [
    "#people_copy = people.copy()\n",
    "train = train_df.sample(frac=1, random_state=5)\n",
    "#new_data = train.sample(frac=0.8, random_state=0)\n",
    "\n",
    "#test = train_df.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3wtIxKBc-NR",
    "outputId": "7a90ae3e-f6a8-4fea-e262-794624377b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL_COLUMN    686\n",
      "DATA_COLUMN     686\n",
      "dtype: int64\n",
      "LABEL_COLUMN\n",
      "0    686\n",
      "Name: count, dtype: int64\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print (train.count())\n",
    "unique_labels = np.unique(train[\"LABEL_COLUMN\"].tolist())\n",
    "label_counts = train[\"LABEL_COLUMN\"].value_counts()\n",
    "print(label_counts)\n",
    "print(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Coefficient for the label distribution: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the Gini Coefficient\n",
    "def gini_coefficient(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # All values are sorted and normalized (making the total equal to 1)\n",
    "    array = array / array.sum()\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1, array.shape[0] + 1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n - 1) * array)) / n)\n",
    "\n",
    "# Calculate the Gini Coefficient for the label counts\n",
    "gini = gini_coefficient(label_counts.values)\n",
    "print(f\"Gini Coefficient for the label distribution: {gini}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comments in testing:  True\n",
      "Null values in testing:  False\n",
      "Null values after drop in testing:  False\n",
      "LABEL_COLUMN    172\n",
      "DATA_COLUMN     172\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "validation_data_file = '../dataset/extracted_files/'+dataset_name+'_test.csv'\n",
    "test_df = pd.read_csv(validation_data_file)\n",
    "test_df.head()\n",
    "print('Unique comments in testing: ', test_df.sentence.nunique() == test_df.shape[0])\n",
    "print('Null values in testing: ', test_df.isnull().values.any())\n",
    "test_df = test_df.dropna()\n",
    "print('Null values after drop in testing: ', test_df.isnull().values.any())\n",
    "test_df['score'] = pd.Categorical(test_df.score, ordered=True).codes\n",
    "test_df['score'].unique()\n",
    "test_df.rename(columns = {'score' : 'LABEL_COLUMN', 'sentence' : 'DATA_COLUMN'}, inplace = True)\n",
    "test_df.DATA_COLUMN.replace(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', '', regex=True, inplace=True)\n",
    "test_df = test_df[['LABEL_COLUMN','DATA_COLUMN']]\n",
    "test = test_df.sample(frac=1, random_state=5)\n",
    "print (test.count())\n",
    "#unique_labels = np.unique(test_data[\"LABEL_COLUMN\"].tolist())\n",
    "#label_counts = test_data[\"LABEL_COLUMN\"].value_counts()\n",
    "#print(label_counts)\n",
    "#print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qxCCr99vgJBx",
    "outputId": "5e471ba3-49c1-4822-a7a7-b47871d2ab5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Labels: 1,\n",
      "Labels:[0]\n"
     ]
    }
   ],
   "source": [
    "uniqueLabels = train_df['LABEL_COLUMN'].unique()\n",
    "print (f'Number of Labels: {len(uniqueLabels)},\\nLabels:{uniqueLabels}')\n",
    "sentences = list(train_df.DATA_COLUMN.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MrXQ6Tw1fuBF"
   },
   "source": [
    "## Load the Model\n",
    "See Load and Save notebooks in this repository to understand how Transformers models cen be:\n",
    "1. Downloaded\n",
    "2. Stored Locally and\n",
    "3. be used from Local Storage.\n",
    "\n",
    "This should be interesting if you work in a cloud environment without Internet connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPqJYYaTEeA2"
   },
   "source": [
    "Here we tell the model that we whish to train on **20 label values** instead of the original 1 label (with 1 or 0 values) for which the original model was designed. This is why the test below tells us that we better should train this model. So, training it we will :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BdCpOa3CvZjo",
    "outputId": "cfdd8879-0ff9-4f2c-a3f5-e3291293733d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at C:\\Users\\el44163/.cache\\huggingface\\transformers\\98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-german-cased/resolve/main/tf_model.h5 from cache at C:\\Users\\el44163/.cache\\huggingface\\transformers\\d59684a4900c4a328fb7083782550d4e554d3bb3e7aac2998cfa97815398e9b2.b7063093ea41ccd755fa8ced83a58867b5f5890f6bba5538ffae78a7b12e58f0.h5\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading file https://huggingface.co/bert-base-german-cased/resolve/main/vocab.txt from cache at C:\\Users\\el44163/.cache\\huggingface\\transformers\\0c57cb5172c1ac6c957d00597dc43c1b8b2a2cb44729a590fd0112612221f746.9a4f439638381be22bb9f116542bdaa5e1d8bb7a09a5f8ef32d9662deaf655a1\n",
      "loading file https://huggingface.co/bert-base-german-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-german-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-german-cased/resolve/main/tokenizer_config.json from cache at C:\\Users\\el44163/.cache\\huggingface\\transformers\\2529d64cc99a539f2103ad09cea0d6459e181d8dc168fe06b32d25ddc68e6d3b.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading configuration file https://huggingface.co/bert-base-german-cased/resolve/main/config.json from cache at C:\\Users\\el44163/.cache\\huggingface\\transformers\\98877e98ee76b3977d326fe4f54bc29f10b486c317a70b6445ac19a0603b00f0.1f2afedb22f9784795ae3a26fe20713637c93f50e2c99101d952ea6476087e5e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-german-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer outputs:  dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    }
   ],
   "source": [
    "max_length = 512\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-german-cased', num_labels=len(uniqueLabels))\n",
    "#model = TFBertForSequenceClassification.from_pretrained('../models/G-SciEdBert', from_pt=True, num_labels=len(uniqueLabels))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased', do_lower_case=True) # tokenizer\n",
    "encodings = tokenizer.batch_encode_plus(sentences,max_length=max_length,pad_to_max_length=True) # tokenizer's encoding method\n",
    "print('tokenizer outputs: ', encodings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "omoxwyaEaH5R",
    "outputId": "42da7204-4083-49db-a3a9-3f46aeef44e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109081344 \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  769       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,082,113\n",
      "Trainable params: 109,082,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OY__mmNzbFPs"
   },
   "source": [
    "## Creating Input Sequences\n",
    "We have two pandas Dataframe objects waiting for us to convert them into suitable objects for the BERT model. We will take advantage of the InputExample function that helps us to create sequences from our dataset. The InputExample function can be called as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YgcKjdFIbCAL",
    "outputId": "36ccb947-f433-442a-ebaa-f4ce69ce9070"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputExample(guid=None, text_a='Hello, world', text_b=None, label=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transformers.InputExample\n",
    "InputExample(guid=None,\n",
    "             text_a = \"Hello, world\",\n",
    "             text_b = None,\n",
    "             label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbU6diuYbNVM"
   },
   "source": [
    "Now we will create two main functions:\n",
    "\n",
    "1 — `convert_data_to_examples`: This will accept our train and test datasets and convert each row into an InputExample object.\n",
    "\n",
    "2 — `convert_examples_to_tf_dataset`: This function will tokenize the InputExample objects, then create the required input format with the tokenized objects, finally, create an input dataset that we can feed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ZobDj7ZibI78"
   },
   "outputs": [],
   "source": [
    "def convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN):\n",
    "  train_InputExamples = train.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN],\n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  validation_InputExamples = test.apply(lambda x: InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this case\n",
    "                                                          text_a = x[DATA_COLUMN],\n",
    "                                                          text_b = None,\n",
    "                                                          label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "  return train_InputExamples, validation_InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "1wUBIWuEbleM"
   },
   "outputs": [],
   "source": [
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train,\n",
    "                                                                           test,\n",
    "                                                                           'DATA_COLUMN',\n",
    "                                                                           'LABEL_COLUMN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "k52dErBYbVst"
   },
   "outputs": [],
   "source": [
    "def convert_examples_to_tf_dataset(examples, tokenizer, max_length=128):\n",
    "    features = [] # -> will hold InputFeatures to be converted later\n",
    "\n",
    "    for e in examples:\n",
    "        # Documentation is really strong for this method, so please take a look at it\n",
    "        input_dict = tokenizer.encode_plus(\n",
    "            e.text_a,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length, # truncates if len(s) > max_length\n",
    "            return_token_type_ids=True,\n",
    "            return_attention_mask=True,\n",
    "            pad_to_max_length=True, # pads to the right by default # CHECK THIS for pad_to_max_length\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids, token_type_ids, attention_mask = (input_dict[\"input_ids\"],\n",
    "            input_dict[\"token_type_ids\"], input_dict['attention_mask'])\n",
    "\n",
    "        features.append(\n",
    "            InputFeatures(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, label=e.label\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def gen():\n",
    "        for f in features:\n",
    "            yield (\n",
    "                {\n",
    "                    \"input_ids\": f.input_ids,\n",
    "                    \"attention_mask\": f.attention_mask,\n",
    "                    \"token_type_ids\": f.token_type_ids,\n",
    "                },\n",
    "                f.label,\n",
    "            )\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
    "        (\n",
    "            {\n",
    "                \"input_ids\": tf.TensorShape([None]),\n",
    "                \"attention_mask\": tf.TensorShape([None]),\n",
    "                \"token_type_ids\": tf.TensorShape([None]),\n",
    "            },\n",
    "            tf.TensorShape([]),\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "n44iQfkQba9M"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN = 'DATA_COLUMN'\n",
    "LABEL_COLUMN = 'LABEL_COLUMN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsahLWQIfsMv",
    "outputId": "efbd9ade-e05a-4fd2-c134-f1571cfa78dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> DATA_COLUMN\n",
      "<class 'str'> LABEL_COLUMN\n"
     ]
    }
   ],
   "source": [
    "print (str(type(DATA_COLUMN)) + ' ' + DATA_COLUMN)\n",
    "print (str(type(LABEL_COLUMN)) + ' ' + LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "GzSyFUoKgbNE",
    "outputId": "71544918-3125-4fa9-d27b-58e349879d27"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL_COLUMN</th>\n",
       "      <th>DATA_COLUMN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0</td>\n",
       "      <td>Wie viel Strom sie haben, hängt davon ab, ob E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>0</td>\n",
       "      <td>Ein Kohlekraftwerk kann jeden Tag 24Stunden gl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>0</td>\n",
       "      <td>Das es eventuell Hochwasser geben könnte. Und ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0</td>\n",
       "      <td>Die Nachteile sind, dass das Wasser aus dem Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "      <td>Es wird nicht immer Strom geben, da Gezeiten a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LABEL_COLUMN                                        DATA_COLUMN\n",
       "293             0  Wie viel Strom sie haben, hängt davon ab, ob E...\n",
       "683             0  Ein Kohlekraftwerk kann jeden Tag 24Stunden gl...\n",
       "680             0  Das es eventuell Hochwasser geben könnte. Und ...\n",
       "514             0  Die Nachteile sind, dass das Wasser aus dem Fl...\n",
       "71              0  Es wird nicht immer Strom geben, da Gezeiten a..."
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BR_puwpBbtid",
    "outputId": "d05cec17-0bbb-41a5-d06e-ee097eb3c0ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2263: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 750 ms\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_InputExamples, validation_InputExamples = convert_data_to_examples(train, test, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "train_data = convert_examples_to_tf_dataset(list(train_InputExamples), tokenizer)\n",
    "train_data = train_data.shuffle(100).batch(32).repeat(2)\n",
    "\n",
    "validation_data = convert_examples_to_tf_dataset(list(validation_InputExamples), tokenizer)\n",
    "validation_data = validation_data.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL_COLUMN    172\n",
      "DATA_COLUMN     172\n",
      "dtype: int64\n",
      "LABEL_COLUMN\n",
      "0    172\n",
      "Name: count, dtype: int64\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print (test.count())\n",
    "unique_labels = np.unique(test[\"LABEL_COLUMN\"].tolist())\n",
    "label_counts = test[\"LABEL_COLUMN\"].value_counts()\n",
    "print(label_counts)\n",
    "print(unique_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Coefficient for the label distribution: 0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate the Gini Coefficient\n",
    "def gini_coefficient(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # All values are sorted and normalized (making the total equal to 1)\n",
    "    array = array / array.sum()\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1, array.shape[0] + 1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2 * index - n - 1) * array)) / n)\n",
    "\n",
    "# Calculate the Gini Coefficient for the label counts\n",
    "gini = gini_coefficient(label_counts.values)\n",
    "print(f\"Gini Coefficient for the label distribution: {gini}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe-9PgI_ckZv"
   },
   "source": [
    "## Configuring the BERT model and Fine-tuning\n",
    "We will use Adam as our optimizer, CategoricalCrossentropy as our loss function, and SparseCategoricalAccuracy as our accuracy metric. Fine-tuning the model for 2 epochs will give us good accuracy, which is great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxypaKh8cg3m",
    "outputId": "fbc15683-fdd8-4ecb-f393-b6b27ed93752",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "44/44 [==============================] - 30s 328ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/2\n",
      "44/44 [==============================] - 12s 274ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "CPU times: total: 37.4 s\n",
      "Wall time: 42.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x207adf21e50>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')])\n",
    "\n",
    "model.fit(train_data, epochs=2, validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQ1f4sbszxJV",
    "outputId": "545aecf0-e8c0-49f0-bcb6-767793eb21f5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../models/G-SciEdBERT_model_combined\\config.json\n",
      "Model weights saved in ../models/G-SciEdBERT_model_combined\\tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model,output_model_name)\n",
    "model.save_pretrained(output_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comments in testing:  False\n",
      "Null values in testing:  False\n",
      "Null values after drop in testing:  False\n",
      "LABEL_COLUMN    9823\n",
      "DATA_COLUMN     9823\n",
      "dtype: int64\n",
      "LABEL_COLUMN\n",
      "0    4508\n",
      "1    4281\n",
      "2     607\n",
      "5     256\n",
      "6      90\n",
      "7      43\n",
      "3      21\n",
      "4      17\n",
      "Name: count, dtype: int64\n",
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "validation_data_file = '../dataset/extracted_files/'+dataset_name+'_test.csv'\n",
    "test_df = pd.read_csv(validation_data_file)\n",
    "test_df.head()\n",
    "print('Unique comments in testing: ', test_df.sentence.nunique() == test_df.shape[0])\n",
    "print('Null values in testing: ', test_df.isnull().values.any())\n",
    "test_df = test_df.dropna()\n",
    "print('Null values after drop in testing: ', test_df.isnull().values.any())\n",
    "test_df['score'] = pd.Categorical(test_df.score, ordered=True).codes\n",
    "test_df['score'].unique()\n",
    "test_df.rename(columns = {'score' : 'LABEL_COLUMN', 'sentence' : 'DATA_COLUMN'}, inplace = True)\n",
    "test_df.DATA_COLUMN.replace(r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+', '', regex=True, inplace=True)\n",
    "test_df = test_df[['LABEL_COLUMN','DATA_COLUMN']]\n",
    "test_data = test_df.sample(frac=1, random_state=5)\n",
    "print (test_data.count())\n",
    "unique_labels = np.unique(test_data[\"LABEL_COLUMN\"].tolist())\n",
    "label_counts = test_data[\"LABEL_COLUMN\"].value_counts()\n",
    "print(label_counts)\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Exception encountered when calling layer \"embeddings\" \"                 f\"(type TFBertEmbeddings).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[9823,512,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResourceGather]\n\nCall arguments received by layer \"embeddings\" \"                 f\"(type TFBertEmbeddings):\n  • input_ids=tf.Tensor(shape=(9823, 512), dtype=int32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(9823, 512), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m validation_labels \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLABEL_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m tf_batch \u001b[38;5;241m=\u001b[39m tokenizer(pred_sentences, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m tf_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m tf_predictions \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(tf_outputs[\u001b[38;5;241m0\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Get index of predicted label for each sentence\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\modeling_tf_utils.py:383\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m main_input \u001b[38;5;241m=\u001b[39m fn_args_and_kwargs\u001b[38;5;241m.\u001b[39mpop(main_input_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    382\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, main_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:1633\u001b[0m, in \u001b[0;36mTFBertForSequenceClassification.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;129m@unpack_inputs\u001b[39m\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;129m@add_start_docstrings_to_model_forward\u001b[39m(BERT_INPUTS_DOCSTRING\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size, sequence_length\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;129m@add_code_sample_docstrings\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1625\u001b[0m     training: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1626\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[TFSequenceClassifierOutput, Tuple[tf\u001b[38;5;241m.\u001b[39mTensor]]:\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m \u001b[38;5;124;03m    labels (`tf.Tensor` or `np.ndarray` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m        Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m        config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m \u001b[38;5;124;03m        `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1633\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1645\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1646\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(inputs\u001b[38;5;241m=\u001b[39mpooled_output, training\u001b[38;5;241m=\u001b[39mtraining)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\modeling_tf_utils.py:383\u001b[0m, in \u001b[0;36munpack_inputs.<locals>.run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m main_input \u001b[38;5;241m=\u001b[39m fn_args_and_kwargs\u001b[38;5;241m.\u001b[39mpop(main_input_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    382\u001b[0m unpacked_inputs \u001b[38;5;241m=\u001b[39m input_processing(func, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, main_input, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfn_args_and_kwargs)\n\u001b[1;32m--> 383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munpacked_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:768\u001b[0m, in \u001b[0;36mTFBertMainLayer.call\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m token_type_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mfill(dims\u001b[38;5;241m=\u001b[39minput_shape, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 768\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# We create a 3D attention mask from a 2D tensor mask.\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;66;03m# Sizes are [batch_size, 1, 1, to_seq_length]\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# this attention mask is more simple than the triangular masking of causal attention\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;66;03m# used in OpenAI GPT, we just need to prepare the broadcast dimension here.\u001b[39;00m\n\u001b[0;32m    782\u001b[0m attention_mask_shape \u001b[38;5;241m=\u001b[39m shape_list(attention_mask)\n",
      "File \u001b[1;32mC:\\ProgramData\\miniconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py:203\u001b[0m, in \u001b[0;36mTFBertEmbeddings.call\u001b[1;34m(self, input_ids, position_ids, token_type_ids, inputs_embeds, past_key_values_length, training)\u001b[0m\n\u001b[0;32m    198\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(\n\u001b[0;32m    199\u001b[0m         tf\u001b[38;5;241m.\u001b[39mrange(start\u001b[38;5;241m=\u001b[39mpast_key_values_length, limit\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m past_key_values_length), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    202\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings, indices\u001b[38;5;241m=\u001b[39mposition_ids)\n\u001b[1;32m--> 203\u001b[0m token_type_embeds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_type_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m position_embeds \u001b[38;5;241m+\u001b[39m token_type_embeds\n\u001b[0;32m    205\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(inputs\u001b[38;5;241m=\u001b[39mfinal_embeddings)\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Exception encountered when calling layer \"embeddings\" \"                 f\"(type TFBertEmbeddings).\n\n{{function_node __wrapped__ResourceGather_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[9823,512,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ResourceGather]\n\nCall arguments received by layer \"embeddings\" \"                 f\"(type TFBertEmbeddings):\n  • input_ids=tf.Tensor(shape=(9823, 512), dtype=int32)\n  • position_ids=None\n  • token_type_ids=tf.Tensor(shape=(9823, 512), dtype=int32)\n  • inputs_embeds=None\n  • past_key_values_length=0\n  • training=False"
     ]
    }
   ],
   "source": [
    "pred_sentences= test_data[\"DATA_COLUMN\"].tolist()\n",
    "validation_labels = test_data[\"LABEL_COLUMN\"].tolist()\n",
    "tf_batch = tokenizer(pred_sentences, max_length=512, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "\n",
    "# Get index of predicted label for each sentence\n",
    "predicted_labels = tf.argmax(tf_predictions, axis=1).numpy()\n",
    "\n",
    "true_positives = 0\n",
    "\n",
    "# output human readable label predictions\n",
    "for i in range(len(pred_sentences)):\n",
    "    predicted_label = predicted_labels[i]\n",
    "    actual_label = validation_labels[i]\n",
    "    if predicted_label == actual_label:\n",
    "        true_positives+=1\n",
    "accuracy = true_positives/len(pred_sentences)\n",
    "print(\"Overall testing Accuracy:\",accuracy )\n",
    "        \n",
    "\n",
    "    \n",
    "#for i in range(len(pred_sentences)):\n",
    "    #print(pred_sentences[i], \": \\n\", str(predicted_labels[i]) +\" with score: \"+ str(tf_predictions[i][predicted_labels[i]].numpy()))\n",
    "    #print (\"Actual Label:\",str(validation_labels[i]) )\n",
    "\n",
    "# Compute accuracy for each label\n",
    "unique_labels = np.unique(validation_labels)\n",
    "label_accuracies = {}\n",
    "\n",
    "for label in unique_labels:\n",
    "    correct_predictions = np.sum((predicted_labels == label) & (validation_labels == label))\n",
    "    total_label_count = np.sum(validation_labels == label)\n",
    "    \n",
    "    accuracy = correct_predictions / total_label_count\n",
    "    label_accuracies[label] = accuracy\n",
    "\n",
    "print(\"Validation accuracy for each label:\", label_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "M7--kUGo034F",
    "outputId": "508d8274-c2ac-42b3-e664-a69e45bb6ef9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/bert_model_gelatin_gender2\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.33.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file ../models/bert_model_gelatin_gender2\\tf_model.h5\n",
      "Some layers from the model checkpoint at ../models/bert_model_gelatin_gender2 were not used when initializing TFBertForSequenceClassification: ['dropout_1101']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ../models/bert_model_gelatin_gender2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n",
      "loading file vocab.txt from cache at C:\\Users\\el44163/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\1dbc166cf8765166998eff31ade2eb64c8a40076\\vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at C:\\Users\\el44163/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\1dbc166cf8765166998eff31ade2eb64c8a40076\\tokenizer_config.json\n",
      "loading configuration file config.json from cache at C:\\Users\\el44163/.cache\\huggingface\\hub\\models--bert-base-uncased\\snapshots\\1dbc166cf8765166998eff31ade2eb64c8a40076\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.33.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model = torch.load(output_model_name)\n",
    "model_name = 'gelatin_gender2'\n",
    "output_model_name = '../models/bert_model_'+model_name\n",
    "#output_model_name = '../models/bert_model_ETS_CH_gelatin'\n",
    "new_model = TFBertForSequenceClassification.from_pretrained(output_model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True) # tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS9SoNm-dD07"
   },
   "source": [
    "Training the model might take a while, so ensure you enabled the GPU acceleration from the Notebook Settings. After our training is completed, we can move onto making sentiment predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2kIo1BtdOai"
   },
   "source": [
    "## Making Predictions\n",
    "I created a list of two reviews I created. The first one is a positive review, while the second one is clearly negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "id": "w2HLb5gFcpL-"
   },
   "outputs": [],
   "source": [
    "pred_sentences = [\"The water is only stirring while the weight is falling. When the weight falls, the paddle will stop stirring.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique comments in training:  True\n",
      "Null values in training:  False\n",
      "Null values after drop in training:  False\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'gelatin'\n",
    "sub_dataset = 'gender1'\n",
    "data_file = '../datasets/'+dataset_name+'/'+sub_dataset+'_test.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "df.head()\n",
    "print('Unique comments in training: ', df.sentence.nunique() == df.shape[0])\n",
    "print('Null values in training: ', df.isnull().values.any())\n",
    "df = df.dropna()\n",
    "print('Null values after drop in training: ', df.isnull().values.any())\n",
    "pred_sentences = list(df['sentence'])\n",
    "actual_labels = list(df['score'])\n",
    "print(len(pred_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rM2YzQrmdXUa"
   },
   "source": [
    "We need to tokenize our reviews with our pre-trained BERT tokenizer. We will then feed these tokenized sequences to our model and run a final softmax layer to get the predictions. We can then use the argmax function to determine whether our sentiment prediction for the review is positive or negative. Finally, we will print out the results with a simple for loop. The following lines do all of these said operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lxD4gyExdTZ6",
    "outputId": "ef8d5fdd-1247-44a7-c4c9-cc75f5880517"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial temperatures and the masses of each should be measured To find the final temperature of the mixture, Qc+Qh = 0 Thus we can set Qc=-Qh, or mCdeltaTc= -mCdeltaTh We know the specific heat of water is a constant so it does not affect the equation deltaTc=Tfinal-Tinitial and deltaTh=Tfinal-Tinitial Since Tfinal will be the same for the final mixture, Tinitial must be known for each water Since mass is also a variable, it needs to be measured Thus the mass and the initial temperatures must be known : \n",
      " 4 with score: 0.5483377\n",
      "\n",
      "We should ensure that when adding the two bowls of water together a temperature of atleast 40(C) is formed The temperature of two substances flows from warmer to colder, so as long as when the two fuse the temperature averages out at least at 40(C), there shouldn;t be an issue dissolving the Gelatin : \n",
      " 2 with score: 0.66361976\n",
      "\n",
      "The original temperature of the gelatin and its amount and the amounts of hot water and cold water The amounts of hot and cold water determine their heat, which is temperature related to mass, which determines how much the gelatin will heat up The original temperature of the gelatin is also a factor : \n",
      " 4 with score: 0.8043595\n",
      "\n",
      "The powder's temp the bowl's temp the hot water's mass and temp the cold water's mass and temp All of it will cool the hot water down meaning you must have engough heat to beat those varibles : \n",
      " 2 with score: 0.7255226\n",
      "\n",
      "the temperature to make sure the temperature is right : \n",
      " 1 with score: 0.7801316\n",
      "\n",
      "the temperature of the hot and cold water and the amount of the water in each if the temperatures are equidistant apart with a center of 40 and the same amount is poured each time, then they will become 40 degrees celcius : \n",
      " 4 with score: 0.8009897\n",
      "\n",
      "Need to check the temperature of each water because if you dont pour the correct temperature water you can mess it up : \n",
      " 2 with score: 0.8627265\n",
      "\n",
      "it will increase the hot water to like 20c becasue it not that hot : \n",
      " 1 with score: 0.7093041\n",
      "\n",
      "The total mass of water being used as well as the measurement of hot water and cold water A larger mass of water will heat and cool different than a smaller mass, and using different measurment/ratios of hot water and cold water will produce different results : \n",
      " 4 with score: 0.8550654\n",
      "\n",
      "The room tempature and powder tempature Because it could 20 degrees in the room : \n",
      " 2 with score: 0.9468786\n",
      "\n",
      "The temperature of the cold and hot water indivudually and how much of the Gelatin powder was put into the bowl The amount of Gelatin powder can influence the temperature of the mixture of hot and cold water Since volume and temperature are inversly proportional, if you have a small ammount of powder, you will have a small temperature and vice versa : \n",
      " 4 with score: 0.6478462\n",
      "\n",
      "amount of hot and cold water This is because depending on the amount of hot and cold water, this can affect what the degree turns out to be : \n",
      " 3 with score: 0.9299341\n",
      "\n",
      "The temperature of both the hot and cold water If we don't know what temperature either of the waters are, there is little way to predict an outcome : \n",
      " 3 with score: 0.98063385\n",
      "\n",
      "Amount, orginally tempature Makes sense : \n",
      " 1 with score: 0.8190053\n",
      "\n",
      "The amount of water and the heat of the water the effectivness of the hotness or coolness of the water is based on its heat energy : \n",
      " 3 with score: 0.6059365\n",
      "\n",
      "Temperature and volume Temperature: 30 degrees Celsius for the cold water and 50 degrees Celsius for the hot so they cancel each other Volume is also important because you need to have the same amount so one doesn't overpower the other : \n",
      " 3 with score: 0.66047525\n",
      "\n",
      "the temperature of the hot water, cold water and the mixture You need to know the temperature of the hot water, cold water and the mixture to know how much it will all change when added together : \n",
      " 3 with score: 0.9769596\n",
      "\n",
      "The exact tempertures of the hot and cold water must be measured The amount of water for each must also be measured The hot and cold water will combine and will undergo thermal equilibrium Seeing the temperture of each type of water will let you know how long it will take for the temperture to get to 40 degrees celsius : \n",
      " 4 with score: 0.6336708\n",
      "\n",
      "Some variables that sould be measured include the volume of the hot and cold water being added and also the actual temperature of both liquids We should know the actual temperature because if the hot water was 76 degrees and the cold water was 1 degree, given a constant volume, then it would be less than 40 degress Volume also matters because if much more cold water was added than warm water, the water would be more cold than warm : \n",
      " 4 with score: 0.79670626\n",
      "\n",
      "The amount of hot and cold water to create the tempature you are looking for Also the amount of Gelatin and the size of the bowl which also play factors what the tempature will be after the experiment is over You first have to be aware of how much space you have to work with (bowl) then the amount of powder because the powder will absorb some of the water Then you have to know how much cold and hot water to mix in order to get 40 degrees celcuis : \n",
      " 4 with score: 0.5373546\n",
      "\n",
      "How much water is being poored into the bowl and what are the temperatures of each liquid measuring cup The same amount of liquid needs to be poored into the mixture from each cup to ensure that heat will spread evenly throughout the water Then the hotter the hot water is compared to 40 degrees clecius, the cold water needs to be that much colder in order to disperse the excess heat more effeicently : \n",
      " 4 with score: 0.5686066\n",
      "\n",
      "Assuming no heat is lost to the surrounding environment before the cold water and hot water are fully mixed, the temperature of the gelatin powder should be measured to insure that it reaches the desired temperature If the powder is already hot or cold then it will affect the temperature taht it reaches because if it is warm, it will turn out warmer; if it is cold,it will be colder : \n",
      " 2 with score: 0.9526268\n",
      "\n",
      "The starting temperature of both solutions of water Both numbers are needed to calculate the percentage needed of each solution to reach 40C : \n",
      " 3 with score: 0.9122291\n",
      "\n",
      "The temperature of both waterrs temperature of the gelatin Both contribute to the results of the goal of 40 degrees celcius : \n",
      " 3 with score: 0.96433175\n",
      "\n",
      "the tempature of both cups off water and amount also the gelatin temp i guess Cause thats what you should measure : \n",
      " 3 with score: 0.7439494\n",
      "\n",
      "the amount of each type of water you would have to measure the amount of water to find out the temp of the water after mixing : \n",
      " 3 with score: 0.91789305\n",
      "\n",
      "If the hot water and cold water is at an average temperature to both add up to over 40 degrees celcius If both cold and hot water don't have the requirements of temperature then the pudding cannot be created : \n",
      " 2 with score: 0.49614522\n",
      "\n",
      "You willl need to know the temperature of the cold water, hot water, and the gelatin You need to know the amount of each substance and their specific heat Variables that affect the final temperature of a substance include the temperature of each individual substance added as each temperature will affect one another to result in a final yield For example adding the same amount of water, one that is 20 degrees Celcius and the other 40, results in a final temperature of 30 degrees Celcius The amount of each substance, for adding twice as much hot water will result in a hotter final substance Finally the specific heat as the amount of heat needed to change the degree of temperature for each substance varies on the substance : \n",
      " 4 with score: 0.6063524\n",
      "\n",
      "the temperature of the to cups of water should be measured, aswell as the mass of the cups when combined Assuming that the environment has no affect of the temperature, the only thing that would matter is the temperature of the water : \n",
      " 3 with score: 0.79976267\n",
      "\n",
      "What temperatures the hot water and the cold water are each at and How much of each liquid you have If one is too hot or too cold they can combine and it will make the temperature above or below 40 degrees celsius The amount of each water can also affect the temperature of the mixture if there is a much bigger volume of one of the temperatures : \n",
      " 4 with score: 0.8519878\n",
      "\n",
      "Variables that should be measured included how big the bowl is, how much gelatin powder there is, distance of hot and cold water from bowl, how much hot and cold water there is These variables help determine how the temperature is able to reach 40Ã‚Â°C The amount of water would help find surface area to volume ratio which could find rate of temperature change : \n",
      " 4 with score: 0.67618936\n",
      "\n",
      "density, volume Due to figuring out that if both cups are unequal then the resutlts will be inaccurate : \n",
      " 1 with score: 0.7199057\n",
      "\n",
      "You should make sure that you do not have too much hot water to where the gelitan gets too hot, but you should also make sure you do not have too much cold water so that the water does not get too cold My reason for this answer is you can not make the pudding if it is too hot or too cold : \n",
      " 2 with score: 0.95376986\n",
      "\n",
      "Get a thermometer to see how much you will need to get to 40C 1 It is common sense 2 The amount of substance added matters 3 It is common sense : \n",
      " 1 with score: 0.7441936\n",
      "\n",
      "Mass of the two waters and the two temperatures of the hot and cold water You can use those two variables to solve for the amount of water needed to be added from both containers to ensure it reaches 40 degrees celcius : \n",
      " 4 with score: 0.7366369\n",
      "\n",
      "The temperatures of the individual waters If you don't know the temperature of the two water samples, you can't determine whether the end result will have a temperature of 40 degrees celsius : \n",
      " 3 with score: 0.9568919\n",
      "\n",
      "the amounts of each substance being added to make sure there is no error in the experiment : \n",
      " 1 with score: 0.6486009\n",
      "\n",
      "the temperature fifferemce and how much cold water compared to warm they are adding becausr bro : \n",
      " 3 with score: 0.957576\n",
      "\n",
      "that when they mix they will not be colder than 40 degrees so the powder will dissolve : \n",
      " 2 with score: 0.84525514\n",
      "\n",
      "Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€žÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€žÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€ž Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“â€˜ Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“â‚¬ Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€˜ Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë† Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™ Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œ(Ã¢â€”Â)Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë† Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë† Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€™Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“â€˜Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€œÃ¢â€“â€œÃ¢â€“Ë†Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€žÃ¢â€â‚¬Ã¢â€“â€žÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“â€žÃ¢â€“â€žÃ¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€žÃ¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“â€žÃ¢â€“Ë†Ã¢â€“â€žÃ¢â€â‚¬Ã¢â€“â€žÃ¢â€“â€žÃ¢â€â‚¬Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“â€žÃ¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“Ë† Ã¢â€“â‚¬Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â‚¬Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â‚¬Ã¢â€“â‚¬Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â‚¬Ã¢â€“â‚¬Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â€žÃ¢â€“â‚¬ Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â‚¬Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€â‚¬Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“â€™Ã¢â€“Ë† Ã¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë†Ã¢â€“â€žÃ¢â€“â€žÃ¢â€“Ë† : \n",
      " 2 with score: 0.50867885\n",
      "\n",
      "j j : \n",
      " 0 with score: 0.48527268\n",
      "\n",
      "the bowl temp idk : \n",
      " 0 with score: 0.45967868\n",
      "\n",
      "The temperatures of the hot and cold water To ensure the mixture reaches a temperature of forty degrees celcius, the person mixing the two containers of water with the gelatin powder should know how hot and how cold their two containers of water are, which will allow them to know for certain whether or not they will be at least forty degrees celcius when fully mixed : \n",
      " 3 with score: 0.9806574\n",
      "\n",
      "The temperatures and amounts of each hot and cold water If you know the temperature and volume of the hot and cold waters you can easily ensure the mixture to be 40 C : \n",
      " 4 with score: 0.8324518\n",
      "\n",
      "The temp of both waters to make sure that there is a temp difference of greater than or equal to 40 degrees Gelatin powder dissolves in water greater than or equal to 40 degrees, so both waters must be measured to see if the gelatin powder will dissolve : \n",
      " 3 with score: 0.89285696\n",
      "\n",
      "It sould be treated to somthing like 80 degrees hot water and colder water to match the temp The reason I choose this answer is because the water need to be balanced : \n",
      " 2 with score: 0.7774614\n",
      "\n",
      "The temperature of the gelatin, the cold water, and the hot water If you know the temperature of both of the waters, then you know how much of each to put in so the mixture is not too hot or too cold You need to kow the gelatin temperature so you know whether or not its closser ot being warm or closer to being cold, and you know how much of each type of water to put in : \n",
      " 3 with score: 0.701748\n",
      "\n",
      "The temperature of the hot and cold water The amount of hot and cold water used How the water is and the amount use needs to be limited so that it doesn't overwhelm the hot water and drain it of its heat : \n",
      " 3 with score: 0.7272652\n",
      "\n",
      "The temperature of both the hot and cold water beforehand and then seeing when mixed together what temperature they reach Also, spillage could occur as well as liquid being left in the cups How hot or cold the waters are will determine if the mixture will reach 40 degrees : \n",
      " 3 with score: 0.5757723\n",
      "\n",
      "the actual temperatures of the hot and cold water before they get mixed as well as the temperature of the gelatin before the waters get mixed in to ensure you get a percise temperature at the end of a mixture you need to get the temperatures of the waters before you mix them in order to ensure they are good temperatures for mixing : \n",
      " 3 with score: 0.93674296\n",
      "\n",
      "The temperature of each sets of water to make sure the hot water is at least 40 degrees, or more if neither of the sets or water are above or at 40 degress then the mixture will not reach 40 degrees : \n",
      " 3 with score: 0.9030031\n",
      "\n",
      "The amount of each cup of water, the temperature of the water You could have the correct temperatures of the water, but if one cup has more water than the other, it would offset the balance, and vice-versa : \n",
      " 4 with score: 0.81853086\n",
      "\n",
      "Temperature of both the hot and cold water Knowing the temperature of the hot and cold water will give you an idea of what temperature the reactants will end up being : \n",
      " 3 with score: 0.93503577\n",
      "\n",
      "the amount of each one if there is to much cold water the total water will be too cold : \n",
      " 3 with score: 0.9736616\n",
      "\n",
      "The temperature of the hot water and the temperature of the cold water, as well as the amounts of each that are poured in, should be measured before they are mixed Since the temperature should be 40 degrees Celsius for the gelatin to dissolve, if there is too much too cold water as compared to the hot water to the point where the mixture doesn't reach 40 degrees, the gelatin will not dissolve : \n",
      " 4 with score: 0.6832461\n",
      "\n",
      "How much of each temperature are in the containers and the exact temperature of each water temperature The mass and temperature in each container is needed to be known in order to correctly ensure that the gelatin is mixed correctly and if not, where the experiment went wrong and how it can be fixed for the next time : \n",
      " 4 with score: 0.8425096\n",
      "\n",
      "The amount of each type of water If the amount of cold water is too much, the temperature will not reach 40 degrees celcius : \n",
      " 3 with score: 0.97338086\n",
      "\n",
      "The amount of cold and hot water, and the actual temperature of the cold and hot water The amount of cold and hot water, plus the temperature, can determine the final heat of the water in the gelatin mix : \n",
      " 4 with score: 0.66202784\n",
      "\n",
      "temperature of the hot water and temperature of the cold water The final tempature for the mixture needs to be at least 40 : \n",
      " 3 with score: 0.9343749\n",
      "\n",
      "The heat of the hot and cold water To make sure that you'll be able to reach the 40 degree mark : \n",
      " 3 with score: 0.89983016\n",
      "\n",
      "How much warm water and how much cold water is getting put in and how much gelatin powder is being added The water you put in need to at least add up to 40 : \n",
      " 3 with score: 0.8212275\n",
      "\n",
      "fasdvaefvsd sfnldrjnglvbndrl : \n",
      " 1 with score: 0.4047644\n",
      "\n",
      "The temperature of the hot and cold water, the amount of water from each cup, and the amount of gelatin should all be measured before the hot and cold water are mixed It is essential to mix the different substances in proportions If too much hot water is mixed with the cold water, or vice versa, the gelatin may not react properly Additionally, if there is too little or too much gelatin or water, the reaction that is desired will not occur because of a lack of proportional mixing : \n",
      " 4 with score: 0.8404873\n",
      "\n",
      "The temperature of the hot and cold water If you don't know the temperatures of both waters, one could be hot and one could be cold : \n",
      " 3 with score: 0.98213047\n",
      "\n",
      "There should be a big enough bowl so the water doesn't spill So you don't have a mess : \n",
      " 2 with score: 0.5282962\n",
      "\n",
      "tempertures and quauntities of each those factors will help determine what combination will reach 40c : \n",
      " 1 with score: 0.5570986\n",
      "\n",
      "the temperature of each cup of water , and the temperature of the outside enviroment you will the know how much to add to balance out the temperature and outside enviroment could effect the temperature : \n",
      " 4 with score: 0.6740499\n",
      "\n",
      "The temperatures of the water should counteract each other to make a combined temperature of at least 40 degrees Celsius the water has to be at least 40 degrees Celsius in order to correctly make the pudding : \n",
      " 3 with score: 0.75816786\n",
      "\n",
      "Yes Because you need to know how much cold water and hot water you need to mix so you make sure the water is warm and not too hot or cold : \n",
      " 2 with score: 0.94425654\n",
      "\n",
      "The temperature of the hot water, the cold water, and the gelatin The temperatures of the hot water, cold water, and gelatin need to be known because they are the subastabces being mixed together and have to reach a temperature of 40 degrees celsius : \n",
      " 3 with score: 0.98064053\n",
      "\n",
      "how hot the hot water is and how cold the cold water is if the hot water is hot enough then even after it is mixed with the cold it could still be warmer than 40 degrees celcius : \n",
      " 3 with score: 0.9781358\n",
      "\n",
      "Amount of gelatin and water added The amount will determine the temperature of the mixture because if there is too much amount, the mixture will not reach the desired temperature : \n",
      " 3 with score: 0.9512789\n",
      "\n",
      "You should not have too much cold water, as you just need water that is at least 40 degrees C This is because you need at least 40 degrees C As long as it is hot enough, the mixtures should work : \n",
      " 3 with score: 0.8730479\n",
      "\n",
      "the temperatures of the water Hot and cold are relative and are not exact temperatures, you need to find exactly what they are in order to get the final temperature : \n",
      " 3 with score: 0.98298657\n",
      "\n",
      "The volume and temperature of both the hot water, the cold water, and the gelatin The different volumes and temperatures of hot water, gelatin powder, and the cold water will make the resulting mixture have different temperatures If there is too much hot water, the resulting mixture will be too hot; If there is too much cold water, the resulting mixture will be too cold If there is too much gelatin powder, the resulting mixture will be closer to room temperature (27 degrees celsius) : \n",
      " 4 with score: 0.5525707\n",
      "\n",
      "tempurature of bowl, gelatin the temperature could make the math go off just enough : \n",
      " 2 with score: 0.9357493\n",
      "\n",
      "The temprature of the gelatin and both waters If the gelatin has energy (heat) it will cause the reaction to function with colder water than it would at room temprature Also, if you add 30* water and only 45* hot water, the temprature remaining will be below 40* and thuss the expierement would reamain useless, so knowing the exact tempratures of the hot and cold water would be mandatory to making sure the water mixes to 40* : \n",
      " 3 with score: 0.9729552\n",
      "\n",
      "The temperature of the water in both of the beakers They should be at a temperature where they would reach 40 degrees celsius when combined To ensure that the mixture reaches a temperature of 40 degrees celsius, the water from both of the beaker must combine to reach 40 degrees celsius This means that the temperature of the hot water and the cold water should not be too far apart to the point where they would not affect each other : \n",
      " 3 with score: 0.98021424\n",
      "\n",
      "The temperatures of the hot and cold water should be measured and the amount of hot and cold being poured in The hot and cold water need to be able to balance each other in such a way that that creat a 40Ã‚Â°C environment If the cold water is extremely cold and the hot water is just barely hot, it could end up much colder than 40Ã‚Â°C Also, if there is alot of cold water and a little hot water, it could also end up too cold : \n",
      " 4 with score: 0.61802167\n",
      "\n",
      "amount of water type added The amount can significantly change the experiment : \n",
      " 1 with score: 0.6681153\n",
      "\n",
      "The temperature of the hot and cold water should be measured first The temperature of the environment should also be measured to account for heat lost due to the environment after the hot and cold water is fully mixed If you know the temperatures of the hot and cold water, then you can determine the temperature of the water once the two waters are poured into the bowl to ensure that it reaches 40*C Knowing the temperature of the environment will also let one determine the heat of the mixture after more time with exposure to the environment : \n",
      " 3 with score: 0.98188615\n",
      "\n",
      "temperature of the hot and cold water amount of hot and cold water time given to mix waters in order for the water to reach 40 C, the temperatures of the water need to equal out also, there needs to be a specific amount of water to equal 40 C also, there needs to be a specific amount of time for the water to mix since it needs time to reach 40 C : \n",
      " 3 with score: 0.5072149\n",
      "\n",
      "The amount if gelatin powder and the ratio of hot water to cold water The gelatin powder should be measurued because too little or too much wouldn't result in what the person wants The hot and cold water should be measured because of the person wants it to be exaclty 40 degrees celcius there can't be too much cold water to make it less than 40 or too much hot water to make it go over 40 : \n",
      " 3 with score: 0.97067297\n",
      "\n",
      "how hot the warm water is and how cold the cold water is this will help determine the end result : \n",
      " 3 with score: 0.96364224\n",
      "\n",
      "the amount of the watters if you have the same amount of water then it would ballance out when you pour it : \n",
      " 3 with score: 0.82077986\n",
      "\n",
      "The temperature of the warm and cold water, pressure and volume, the temperature of the gelatin The temperatures should be measured because they will determine how much the gelatin's temp will raise and if it will reach 40 degrees C The pressure and volume should be held constant in order to keep the experiment accurate : \n",
      " 3 with score: 0.6219802\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = new_model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "\n",
    "# Get index of predicted label for each sentence\n",
    "pred_label = tf.argmax(tf_predictions, axis=1).numpy()\n",
    "num_classes = tf_predictions.shape[1]\n",
    "\n",
    "# output human readable label predictions\n",
    "for i in range(len(pred_sentences)):\n",
    "    print(pred_sentences[i], \": \\n\", str(pred_label[i]) +\" with score: \"+ str(tf_predictions[i][pred_label[i]].numpy()))\n",
    "  #print(pred_sentences[i], \": \\n\", str(index2label[label[i]]) +\" with score: \"+ str(tf_predictions[i][label[i]].numpy()))\n",
    "    print ()\n",
    "with open('../outputfiles/'+model_name+'Model_'+sub_dataset+'_w_all_probs.csv', 'w',encoding=\"utf-8\", newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    # Writing headers\n",
    "    headers = ['Sentence', 'Actual Score', 'Predicted Score', 'Predicted Score Probability']\n",
    "    headers += [f'Probability_Score_{i}' for i in range(num_classes)]\n",
    "    csvwriter.writerow(headers)\n",
    "\n",
    "    # Write data\n",
    "    for i in range(len(pred_sentences)):\n",
    "        sentence = pred_sentences[i]\n",
    "        actual_score = actual_labels[i]  # or any other method to obtain the actual score\n",
    "        bert_score = pred_label[i]\n",
    "        probability = tf_predictions[i][pred_label[i]].numpy()\n",
    "        probabilities = tf_predictions[i].numpy().tolist()\n",
    "\n",
    "        # Write the row to the CSV file\n",
    "        csvwriter.writerow([sentence, actual_score, bert_score, probability] + probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batch = tokenizer(pred_sentences, max_length=128, padding=True, truncation=True, return_tensors='tf')\n",
    "tf_outputs = new_model(tf_batch)\n",
    "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
    "tf_predictions\n",
    "tf.argmax(tf_predictions, axis=1).numpy()\n",
    "index2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUd8tmWUnK28"
   },
   "source": [
    "## Debugging the Final Tensor Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDRGxQh_V8bt",
    "outputId": "5182dad6-03ad-4915-83d3-d40bbc9d4b3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 20])"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRDxUOJmgvK4",
    "outputId": "d3d5c68a-3707-4af3-a049-e4455c4e1c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[1.9084792e-04 3.4088054e-04 2.0756450e-04 8.6477579e-05 2.9989792e-04\n",
      " 2.6212877e-04 1.9374983e-04 3.5850867e-04 1.5933276e-04 9.9522001e-01\n",
      " 4.5725811e-04 8.2916165e-05 3.6863686e-04 1.2279976e-04 2.3117411e-04\n",
      " 1.3213107e-04 3.1335116e-04 4.4700602e-04 2.9876176e-04 2.2643096e-04], shape=(20,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[2.1327195e-04 4.0231278e-04 1.5158435e-04 1.2487071e-03 1.2888614e-03\n",
      " 1.4331866e-03 4.6543666e-04 1.8467591e-04 4.1545741e-04 3.4950839e-04\n",
      " 1.3036636e-03 9.8752570e-01 1.5377196e-03 3.4859296e-04 4.5611229e-04\n",
      " 5.4127991e-04 2.9390829e-04 9.1435417e-04 2.4715456e-04 6.7858823e-04], shape=(20,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.00853875 0.00138843 0.036679   0.01549945 0.00269004 0.00482676\n",
      " 0.03897305 0.00894227 0.06801455 0.00392437 0.00970633 0.0075493\n",
      " 0.00154941 0.44692346 0.00302002 0.18781705 0.02925803 0.00800841\n",
      " 0.01692865 0.09976259], shape=(20,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[0.00210652 0.32576597 0.08870737 0.05647071 0.01478916 0.450415\n",
      " 0.00654897 0.0011105  0.00139022 0.00533823 0.00271917 0.01810479\n",
      " 0.00990271 0.00076807 0.00862284 0.00325798 0.00087717 0.0009407\n",
      " 0.00067962 0.00148436], shape=(20,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tf_predictions)):\n",
    "  print (tf_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjcFubhmhFQB",
    "outputId": "b591d960-32ee-406c-9149-2c761a2e01f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.00019084792, shape=(), dtype=float32) - tf.Tensor(0.00034088054, shape=(), dtype=float32)\n",
      "tf.Tensor(0.00021327195, shape=(), dtype=float32) - tf.Tensor(0.00040231278, shape=(), dtype=float32)\n",
      "tf.Tensor(0.008538753, shape=(), dtype=float32) - tf.Tensor(0.0013884273, shape=(), dtype=float32)\n",
      "tf.Tensor(0.0021065164, shape=(), dtype=float32) - tf.Tensor(0.32576597, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tf_predictions)):\n",
    "  print (str(tf_predictions[i][0]) + ' - ' + str(tf_predictions[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q88Ppt5Dh9yb",
    "outputId": "96c35101-ce0a-4141-fcef-8220f344e7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9925568\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tf_predictions)):\n",
    "  print(tf_predictions[i][label[i]].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBDcRsbWt74i"
   },
   "source": [
    "Also, with the code above, you can predict as many reviews as possible.\n",
    "\n",
    "# Congratulations\n",
    "\n",
    "You have successfully built a transformers network with a pre-trained BERT model and achieved ~93% accuracy on the newsgroups classification analysis of the 20 Newsgroup reviews dataset! If you are curious about saving your model, I would like to direct you to the [Keras Documentation](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model). After all, to efficiently use an API, one must learn how to read and use the documentation."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
